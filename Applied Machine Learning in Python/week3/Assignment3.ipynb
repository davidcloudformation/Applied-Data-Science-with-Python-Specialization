{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment3dt.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GFNaJ9_Okia",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "_You are currently looking at **version 1.2** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-machine-learning/resources/bANLa) course resource._\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj4Tj5m4Okib",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 3 - Evaluation\n",
        "\n",
        "In this assignment you will train several models and evaluate how effectively they predict instances of fraud using data based on [this dataset from Kaggle](https://www.kaggle.com/dalpozz/creditcardfraud).\n",
        " \n",
        "Each row in `fraud_data.csv` corresponds to a credit card transaction. Features include confidential variables `V1` through `V28` as well as `Amount` which is the amount of the transaction. \n",
        " \n",
        "The target is stored in the `class` column, where a value of 1 corresponds to an instance of fraud and 0 corresponds to an instance of not fraud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyJdVl6HY7TN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZgExVUTOkic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aazY5zLfOkig",
        "colab_type": "text"
      },
      "source": [
        "### Question 1\n",
        "Import the data from `fraud_data.csv`. What percentage of the observations in the dataset are instances of fraud?\n",
        "\n",
        "*This function should return a float between 0 and 1.* "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A44E2pAoPYTq",
        "colab_type": "text"
      },
      "source": [
        "(21693, 30)\n",
        "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
        "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
        "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class'],\n",
        "      dtype='object')\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 21693 entries, 0 to 21692\n",
        "Data columns (total 30 columns):\n",
        "V1        21693 non-null float64\n",
        "V2        21693 non-null float64\n",
        "V3        21693 non-null float64\n",
        "V4        21693 non-null float64\n",
        "V5        21693 non-null float64\n",
        "V6        21693 non-null float64\n",
        "V7        21693 non-null float64\n",
        "V8        21693 non-null float64\n",
        "V9        21693 non-null float64\n",
        "V10       21693 non-null float64\n",
        "V11       21693 non-null float64\n",
        "V12       21693 non-null float64\n",
        "V13       21693 non-null float64\n",
        "V14       21693 non-null float64\n",
        "V15       21693 non-null float64\n",
        "V16       21693 non-null float64\n",
        "V17       21693 non-null float64\n",
        "V18       21693 non-null float64\n",
        "V19       21693 non-null float64\n",
        "V20       21693 non-null float64\n",
        "V21       21693 non-null float64\n",
        "V22       21693 non-null float64\n",
        "V23       21693 non-null float64\n",
        "V24       21693 non-null float64\n",
        "V25       21693 non-null float64\n",
        "V26       21693 non-null float64\n",
        "V27       21693 non-null float64\n",
        "V28       21693 non-null float64\n",
        "Amount    21693 non-null float64\n",
        "Class     21693 non-null int64\n",
        "dtypes: float64(29), int64(1)\n",
        "memory usage: 5.0 MB\n",
        "None"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oawq7NBPOkig",
        "colab_type": "code",
        "outputId": "53397961-10e6-4f21-f7bf-d850503b02aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def answer_one():\n",
        "    df = pd.read_csv('fraud_data.csv')\n",
        "#     print(df.shape)\n",
        "#     print(df.keys())\n",
        "#     print(df.info())\n",
        "    ans = len(df[df['Class']== 1]) / len(df[df['Class']== 0])\n",
        "    \n",
        "    # Your code here\n",
        "    \n",
        "    return ans\n",
        "\n",
        "answer_one()  "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.016684632328818484"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v1mVg8DOkij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use X_train, X_test, y_train, y_test for all of the following questions\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('fraud_data.csv')\n",
        "\n",
        "X = df.iloc[:,:-1]\n",
        "y = df.iloc[:,-1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fn2UEQrzOkil",
        "colab_type": "text"
      },
      "source": [
        "### Question 2\n",
        "\n",
        "Using `X_train`, `X_test`, `y_train`, and `y_test` (as defined above), train a dummy classifier that classifies everything as the majority class of the training data. What is the accuracy of this classifier? What is the recall?\n",
        "\n",
        "*This function should a return a tuple with two floats, i.e. `(accuracy score, recall score)`.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYf7p4PwOkim",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5234917-b547-48d6-b440-c4f2171ce8d7"
      },
      "source": [
        "def answer_two():\n",
        "    from sklearn.dummy import DummyClassifier\n",
        "    from sklearn.metrics import recall_score, accuracy_score\n",
        "    \n",
        "    # Your code here\n",
        "    \n",
        "    dummy_majority = DummyClassifier(strategy = 'most_frequent').fit(X_train, y_train)\n",
        "    # Therefore the dummy 'most_frequent' classifier always predicts class 0\n",
        "    y_dummy_predictions = dummy_majority.predict(X_test)\n",
        "\n",
        "    ans = (accuracy_score(y_test, y_dummy_predictions), recall_score(y_test, y_dummy_predictions))\n",
        "    \n",
        "    return ans\n",
        "answer_two()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9852507374631269, 0.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtjGBgBxOkiq",
        "colab_type": "text"
      },
      "source": [
        "### Question 3\n",
        "\n",
        "Using X_train, X_test, y_train, y_test (as defined above), train a SVC classifer using the default parameters. What is the accuracy, recall, and precision of this classifier?\n",
        "\n",
        "*This function should a return a tuple with three floats, i.e. `(accuracy score, recall score, precision score)`.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMCK5XtfOkir",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c8958f2-2a57-4192-e2f3-769784d59d37"
      },
      "source": [
        "def answer_three():\n",
        "    from sklearn.metrics import recall_score, precision_score, accuracy_score\n",
        "    from sklearn.svm import SVC\n",
        "\n",
        "    # Your code here\n",
        "    svm = SVC().fit(X_train, y_train)\n",
        "    y_predictions = svm.predict(X_test)\n",
        "    \n",
        "    ans = (accuracy_score(y_test, y_predictions), recall_score(y_test, y_predictions), precision_score(y_test, y_predictions))\n",
        "    \n",
        "    return ans\n",
        "answer_three()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9907817109144543, 0.375, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Aj70ypgOkiu",
        "colab_type": "text"
      },
      "source": [
        "### Question 4\n",
        "\n",
        "Using the SVC classifier with parameters `{'C': 1e9, 'gamma': 1e-07}`, what is the confusion matrix when using a threshold of -220 on the decision function. Use X_test and y_test.\n",
        "\n",
        "*This function should return a confusion matrix, a 2x2 numpy array with 4 integers.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sCxp5GhOkiu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "eb5d3b8c-caf5-43ca-90ac-e0d336adb1ea"
      },
      "source": [
        "def answer_four():\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    from sklearn.svm import SVC\n",
        "\n",
        "    # Your code here\n",
        "    svm = SVC(C = 1e9, gamma = 1e-07).fit(X_train, y_train)\n",
        "    svm_predicted = svm.decision_function(X_test) > -220\n",
        "    \n",
        "#     print(svm_predicted)\n",
        "    \n",
        "    confusion = confusion_matrix(y_test, svm_predicted)\n",
        "    \n",
        "    ans = confusion\n",
        "    \n",
        "    return ans\n",
        "\n",
        "answer_four()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5320,   24],\n",
              "       [  14,   66]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVl10LhmOkix",
        "colab_type": "text"
      },
      "source": [
        "### Question 5\n",
        "\n",
        "Train a logisitic regression classifier with default parameters using X_train and y_train.\n",
        "\n",
        "For the logisitic regression classifier, create a precision recall curve and a roc curve using y_test and the probability estimates for X_test (probability it is fraud).\n",
        "\n",
        "Looking at the precision recall curve, what is the recall when the precision is `0.75`?\n",
        "\n",
        "Looking at the roc curve, what is the true positive rate when the false positive rate is `0.16`?\n",
        "\n",
        "*This function should return a tuple with two floats, i.e. `(recall, true positive rate)`.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wawFtynMOkiy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bba4edf2-d25c-43f9-aa07-28083f605525"
      },
      "source": [
        "def answer_five():\n",
        "        \n",
        "    # Your code here\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.metrics import precision_recall_curve\n",
        "    from sklearn.metrics import roc_curve\n",
        "\n",
        "    lr = LogisticRegression().fit(X_train, y_train)\n",
        "    \n",
        "    y_scores_lr = lr.fit(X_train, y_train).decision_function(X_test)\n",
        "    \n",
        "#     lr_predicted = lr.predict(X_test)\n",
        "    \n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, y_scores_lr)\n",
        "    closest_zero_p = np.argmin(np.abs(precision-0.75))\n",
        "#     closest_zero_p = precision[closest_zero]\n",
        "    closest_zero_r = recall[closest_zero_p]\n",
        "    \n",
        "#     print(closest_zero_r)\n",
        "    \n",
        "    \n",
        "    fpr_lr, tpr_lr, _ = roc_curve(y_test, y_scores_lr)\n",
        "#     roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
        "    \n",
        "    closest_zero_fpr_lr = np.argmin(np.abs(fpr_lr - 0.16))\n",
        "#     closest_zero_p = precision[closest_zero]\n",
        "    closest_zero_tpr_lr = recall[closest_zero_fpr_lr]\n",
        "    \n",
        "#     print(closest_zero_tpr_lr)\n",
        "\n",
        "    \n",
        "#     y_proba_lr = lr.fit(X_train, y_train).predict_proba(X_test)\n",
        "    \n",
        "#     confusion = confusion_matrix(y_test, lr_predicted)\n",
        "\n",
        "    ans = (closest_zero_r, closest_zero_tpr_lr)\n",
        "    \n",
        "    return ans\n",
        "answer_five()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.825, 0.9875)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxfsqHrjOki2",
        "colab_type": "text"
      },
      "source": [
        "### Question 6\n",
        "\n",
        "Perform a grid search over the parameters listed below for a Logisitic Regression classifier, using recall for scoring and the default 3-fold cross validation.\n",
        "\n",
        "`'penalty': ['l1', 'l2']`\n",
        "\n",
        "`'C':[0.01, 0.1, 1, 10, 100]`\n",
        "\n",
        "From `.cv_results_`, create an array of the mean test scores of each parameter combination. i.e.\n",
        "\n",
        "|      \t| `l1` \t| `l2` \t|\n",
        "|:----:\t|----\t|----\t|\n",
        "| **`0.01`** \t|    ?\t|   ? \t|\n",
        "| **`0.1`**  \t|    ?\t|   ? \t|\n",
        "| **`1`**    \t|    ?\t|   ? \t|\n",
        "| **`10`**   \t|    ?\t|   ? \t|\n",
        "| **`100`**   \t|    ?\t|   ? \t|\n",
        "\n",
        "<br>\n",
        "\n",
        "*This function should return a 5 by 2 numpy array with 10 floats.* \n",
        "\n",
        "*Note: do not return a DataFrame, just the values denoted by '?' above in a numpy array. You might need to reshape your raw result to meet the format we are looking for.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QrIqVW0Oki3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "65f6adc0-c692-40c6-cdfa-8ef14d65789c"
      },
      "source": [
        "def answer_six():    \n",
        "    from sklearn.model_selection import GridSearchCV\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "    # Your code here\n",
        "    lr = LogisticRegression()\n",
        "\n",
        "    grid_values = {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}\n",
        "\n",
        "    # default metric to optimize over grid parameters\n",
        "    grid_lr = GridSearchCV(lr, param_grid = grid_values, scoring = 'recall')\n",
        "    grid_lr.fit(X_train, y_train)\n",
        "    \n",
        "#     print(grid_lr.cv_results_['mean_test_score'].reshape(5,2))\n",
        "    ans = np.array(grid_lr.cv_results_['mean_test_score'].reshape(5,2))\n",
        " \n",
        "    return ans\n",
        "\n",
        "answer_six()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.66666667, 0.76086957],\n",
              "       [0.80072464, 0.80434783],\n",
              "       [0.8115942 , 0.8115942 ],\n",
              "       [0.80797101, 0.8115942 ],\n",
              "       [0.80797101, 0.80797101]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_aG6YcpOki7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "e496da6e-0412-443f-f800-6e60ed68c796"
      },
      "source": [
        "# Use the following function to help visualize results from the grid search\n",
        "def GridSearch_Heatmap(scores):\n",
        "#     %matplotlib notebook\n",
        "    %matplotlib inline\n",
        "\n",
        "    import seaborn as sns\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.figure()\n",
        "    sns.heatmap(scores.reshape(5,2), xticklabels=['l1','l2'], yticklabels=[0.01, 0.1, 1, 10, 100])\n",
        "    plt.yticks(rotation=0);\n",
        "\n",
        "GridSearch_Heatmap(answer_six())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXZI6xsAuSR1jYJekjjGwS1LH/D9hrn0ybAeOMQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6GDBUC_YmxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}